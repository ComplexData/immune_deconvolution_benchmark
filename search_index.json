[
["index.html", "Benchmarking methods for estimating immune cell abundance from bulk RNA-sequencing data (supplementary information) 1 Introduction", " Benchmarking methods for estimating immune cell abundance from bulk RNA-sequencing data (supplementary information) manuscript in preparation Gregor Sturm\\(^{1,2}\\) Tatsiana Aneichyk\\(^1\\) \\(^1\\)Pieris Pharmaceuticals GmbH, Lise-Meitner-Straße 30, 85354 Freising, Germany \\(^2\\)Experimental Bioinformatics, TUM School of Life Sciences Weihenstephan, Technical University of Munich, Maximus-von-Imhof-Forum 3, 85354 Freising, Germany 2018-10-02 1 Introduction This document is supplementary information for Sturm, G. and Aneichyk T. Benchmarking methods for estimating immune cell abundance from bulk RNA-sequencing data, Manuscript in preparation. This document elaborates step-by-step how we derive our results, shows supplementary figures to support our study and serves as an open-source pipeline to reproduce our results. The source code and instructions how to run the benchmark are available from GitHub: grst/immune_deconvolution_benchmark "],
["input-data.html", "2 Input data 2.1 cell type hierarchy 2.2 Single cell data for simulated mixtures 2.3 Immune cell reference samples 2.4 8 PBMC samples from Hoek et al. (2015) 2.5 3 ovarian cancer ascites samples from Schelker et al. (2017) 2.6 4 metastatic melanoma samples from Racle et al. (2017) 2.7 Data sanity checks", " 2 Input data In this chapter, we load and preprocess the datasets we use in this study Dataset Reference A dataset of more than 11,000 single cancer and immune cells, classified by cell type Schelker et al. (2017) 50 Immune cell reference samples from 5 studies Curated by Finotello et al. (2017) 3 ovarian cancer ascites samples (RNAseq + FACS) Schelker et al. (2017) 8 PBMC samples (RNAseq + FACS) Hoek et al. (2015) 4 metastatic melanoma samplese (RNAseq + FACS) Racle et al. (2017) 2.1 cell type hierarchy We use a hierachy of immune cell types to map the cell types between different methods and datasets. The following figure shows this hierarchy visualized as a tree Figure 2.1: Hierarchy of immune cell types used for mapping cell types between methods and datasets. 2.2 Single cell data for simulated mixtures In this study, we make use of the single cell dataset curated by Schelker et al. (2017). They aggregated single cell sequencing data from different sources resulting in a set of more than 11,000 single cells. They classified the cells using at set of 45 marker genes into 12 categories: 2 cancer types (Melanoma cell, Ovarian carcinoma cell), 7 immune cells (B cell, T cell CD8+, T cell CD4+ (non-regulatory), Macrophage/Monocyte, T cell regulatory (Tregs), Dendritic cell, NK cell), 2 other cells (Cancer associated fibroblast, Endothelial cell) and Unknown cells which could not have been classified unambiguously. Unknown cells are excluded from the downstream analysis. The dataset consists of single cells from PBMC, melanoma and ovarian cancer ascites. As we are interested in the deconvolution of cancer samples, we exclude the PBMC cells from all downstream analyses. Table 2.1: The 11434 single cells by cell type cell_type n B cell 646 Cancer associated fibroblast 132 Dendritic cell 140 Endothelial cell 71 Macrophage/Monocyte 2227 Melanoma cell 1310 NK cell 198 Ovarian carcinoma cell 300 PBMC 3942 T cell CD4+ (non-regulatory) 1196 T cell CD8+ 1130 T cell regulatory (Tregs) 142 Figure 2.2: tSNE-clustering of the ~12,000 single cells from Schelker et al. (2017). 2.3 Immune cell reference samples RNAseq samples of pure immune cells of 10 types from 5 studies curated by Finotello et al. (2017). Table 2.2: List of immune cell reference samples 2.4 8 PBMC samples from Hoek et al. (2015) Table 2.2: Flow cytometry estimates of Hoek et al. 2.5 3 ovarian cancer ascites samples from Schelker et al. (2017) Each sample has two technical replicates. We merge the two replicates by taking the mean for each gene. ## &lt;table&gt; ## &lt;caption&gt;(#tab:mytab)Flow cytometry estimates of Schelker et al. &lt;/caption&gt; ## &lt;/table&gt; The samples have also been profiled by single cell RNA sequencing. The following table shows the cell count for each sample. Table 2.3: Single cell count per ovarian cancer ascites sample. donor sum(cell_count) 7873M 864 7882M 902 7892M 773 2.6 4 metastatic melanoma samples from Racle et al. (2017) Table 2.2: Flow cytometry estimates of Racle et al. 2.7 Data sanity checks Here, we plot the distributions of the different gene expression datasets to ensure that everything looks like we expect it to, e.g. if all datasets are on non-log scale. Figure 2.3: Histogram of gene expression data of all datasets Figure 2.4: Histogram of log-tranformed gene expression data of all datasets The mean values of all datasets: mean(c(exprs(single_cell_schelker$eset))) mean(c(racle$expr_mat)) mean(c(schelker_ovarian$expr_mat)) mean(c(hoek$expr_mat)) mean(c(immune_cell_reference$expr_mat)) ## [1] 0.7163828 ## [1] 29.20031 ## [1] 35.24549 ## [1] 51.61823 ## [1] 17.04449 save.image(file=&quot;../results/cache/input_data.rda&quot;, compress=FALSE) References "],
["validitiy-of-single-cell-rna-seq-as-reference.html", "3 Validitiy of single cell RNA-seq as reference 3.1 Compare simululated to genuine bulk samples 3.2 Enrichment analysis: Test for systematic Bias 3.3 Compare predicted fractions 3.4 Correlation with immune reference samples.", " 3 Validitiy of single cell RNA-seq as reference Since we rely on simulated bulk RNA-seq samples generated from scRNA-seq data, we first investigate if this approach is valid and will give reasonable estimates of the methods’s performances. We conduct the following analyses: * Compare simulated bulk samples with a corresponding genuine bulk sample. * Check if immune-realted genes are subject to a systematic bias. * Compare the predicted fractions of all methods on bulk vs. simulated samples. * Compare simulated bulk samples with a reference immune cell sample of the same cell type. 3.1 Compare simululated to genuine bulk samples bulk_mean = sapply(colnames(schelker_ovarian$expr_mat), function(donor) { ind = pData(single_cell_schelker$eset)$donor == donor apply(exprs(single_cell_schelker$eset)[,ind], 1, mean) }) bulk_mean = apply(bulk_mean, 2, scale_to_million) Figure 3.1: Correlation of simulated bulk samples with corresponding genuine bulk RNA-seq samples. Genes used in the signatures of quanTIseq, EPIC, CIBERSORT and MCP-counter are shown in blue. 3.1.1 Log ratio Next, we calculate the sc-bulk log ratio, by \\[log(sc+1)/log(bulk+1)\\], We observe that the sc-bulk log ratio showes asymmetry: more genes show increased sc-aggregate expression rather than decreased sc-aggregate expression. 3.2 Enrichment analysis: Test for systematic Bias What are these genes that seem to be higher expressed in single-cell aggregates than bulk? We take the geometric mean of the log ratio and run BioQC, using gene ontology (BP and CC terms) as the knowledgebase. geomMean &lt;- function(x) 10^(mean(log10(x))) avgData &lt;- expr_all %&gt;% group_by(gene_symbol) %&gt;% summarise(MeanBulk=geomMean(bulk), MeanSc=geomMean(single_cell_aggregate), MeanScBulkLogRatio=geomMean(ScBulkLogRatio)) ## translate gene symbol into EntrezIds gsIDs &lt;- AnnotationDbi::select(org.Hs.eg.db, avgData$gene_symbol, c(&quot;ENTREZID&quot;), &quot;SYMBOL&quot;) ## &#39;select()&#39; returned 1:many mapping between keys and columns annoAvgData &lt;- avgData %&gt;% inner_join(gsIDs, by=c(&quot;gene_symbol&quot;=&quot;SYMBOL&quot;)) %&gt;% rename(GeneID=ENTREZID) %&gt;% filter(!is.na(GeneID)) %&gt;% dplyr::rename(GeneSymbol = gene_symbol) %&gt;% dplyr::select(GeneID, GeneSymbol, MeanBulk, MeanSc, MeanScBulkLogRatio) ## build up a list of GO gene-sets go &lt;- AnnotationDbi::select(org.Hs.eg.db, annoAvgData$GeneID, c(&quot;GO&quot;), &quot;ENTREZID&quot;) %&gt;% filter(ONTOLOGY %in% c(&quot;BP&quot;,&quot;CC&quot;), EVIDENCE %in% c(&quot;EXP&quot;, &quot;IDA&quot;, &quot;IPI&quot;, &quot;IMP&quot;, &quot;IGI&quot;, &quot;IEP&quot;)) ## &#39;select()&#39; returned 1:many mapping between keys and columns goList &lt;- with(go, split(ENTREZID, GO)) goMatchList &lt;- sapply(goList, function(x) match(x, annoAvgData$GeneID)) goMatchListLen &lt;- sapply(goMatchList, length) goBioQClist &lt;- goMatchList[goMatchListLen&gt;=5 &amp; goMatchListLen&lt;=1000] ## Run two-sided Wilcoxon-Mann-Whitney test using sc-bulk log ratios goBioQCp &lt;- wmwTest(annoAvgData$MeanScBulkLogRatio, goBioQClist, valType=&quot;p.two.sided&quot;) goBioQCq &lt;- wmwTest(annoAvgData$MeanScBulkLogRatio, goBioQClist, valType=&quot;Q&quot;) goBioQClistAnno &lt;- AnnotationDbi::select(GO.db, names(goBioQClist), c(&quot;ONTOLOGY&quot;, &quot;TERM&quot;), &quot;GOID&quot;) ## &#39;select()&#39; returned 1:1 mapping between keys and columns goBioQCres &lt;- cbind(goBioQClistAnno, GeneCount=sapply(goBioQClist, length), BioQC.twosided.pvalue=goBioQCp, BioQC.Qvalue=goBioQCq, FDR=p.adjust(goBioQCp, &quot;BH&quot;), Bonferroni=p.adjust(goBioQCp, &quot;bonferroni&quot;)) Below we display the terms that, under moderate stringency of filtering (Benjamini-Hochberg FDR&lt;0.01), shows significant enrichment in either direction. subset(goBioQCres, FDR&lt;0.01) %&gt;% arrange(BioQC.Qvalue) %&gt;% DT::datatable() Interstingly, there are many terms that are highly significantly over- or underrepresented in simulated versus genuine bulk RNA-seq samples. We currently have no explanation for that. 3.2.1 Immune-relevant genes are consistent between sc and bulk data. We notice that among these significantly enriched gene-sets above, no gene-sets are directly involved in immune response, cytokine/interleukin/chemokine response. Alternatively, we show these immune-relevant gene-sets and their results by an incomprehensive keyword search, to further demonstrating that they do not show strong difference between sc-aggregated and bulk data. isImmune &lt;- with(goBioQCres, grepl(&quot;immune\\\\b&quot;, TERM, ignore.case=TRUE) | grepl(&quot;inflammation\\\\b&quot;, TERM, ignore.case=TRUE) | grepl(&quot;cytokine\\\\b&quot;, TERM, ignore.case=TRUE) | grepl(&quot;chemokine\\\\b&quot;, TERM, ignore.case=TRUE) | grepl(&quot;interleukin\\\\b&quot;, TERM, ignore.case=TRUE) | grepl(&quot;antigen\\\\b&quot;, TERM, ignore.case=TRUE) | grepl(&quot;macrophage\\\\b&quot;, TERM, ignore.case=TRUE) | grepl(&quot;dendritic cell\\\\b&quot;, TERM, ignore.case=TRUE)) immuneRes &lt;- goBioQCres %&gt;% filter(isImmune) immuneRes %&gt;% arrange(FDR) %&gt;% DT::datatable() All in all the bulk expression data and aggregated single-cell data are concordant, using a very rough method (non-parameterized gene-set enrichment test with BioQC), we observe that some classes of genes, such as protein ubiquitination/deubiquitination, spindle organization, and plama membrane genes, show tendency to be over- od under-represented in single-cell aggregates than bulk data. The reason of this observation is not clear. However, we note that, by a limited keyword-search, we found that there is no significant enrichment of gene-ontology terms invovled in immune response that are significantly different between scRNA and bulk data. This further underlines the legibility of using this particular pair of aggregated single-cell data and paired bulk sequencing data to benchmark different methods. 3.3 Compare predicted fractions Most importantly, we ask how consistent the methods’ predictions are on simulated vs. genuine bulk RNA-seq samples. We run all methods on both datasets and compare the results. Figure 3.2: Correlation of the methods’ predictions on both simulated and genuine bulk RNA-seq samples The results show a strong correlation between both datasets and suggest that the approach is valid in general. The poor overlap of xCell is proabably due to the fact that there is little variance between the samples which xCell requires to compute a meaningful score (see their README on GitHub). To demonstrate that this is the case, we run xCell on the same sample, but this time include 50 immune cell reference samples in the run. By adding additional samples, we add additional variance which enables xCell to compute a meaningful score. Figure 3.3: Correlation of xCell’s prediction on both simulated and genuine bulk RNA-seq samples, including additional samples to increase the variance. 3.4 Correlation with immune reference samples. To demonstrate that the simulated bulk samples are also biologically meaningflu, we generate simulated bulk samples of different immune cell types and correlate them with reference profiles of pure immune cells. Figure 3.4: Correlation of simulated bulk samples of a certain immune cell type (y-axis) with immune cell reference samples (x-axis) In general, the highest correlation is observed between the expression of the sorted cells and the simulated bulk sample. However, the simulated Dendritic cells do not correlate well with any of the reference profiles. "],
["simulation-benchmark.html", "4 Simulation benchmark 4.1 Average fraction of tumour cells 4.2 Create simulated bulk tissues 4.3 Run the deconvolution 4.4 Results", " 4 Simulation benchmark In this chapter, we will use single cell data from Schelker et al. (2017) to create simulated bulk RNAseq samples of which we know the true cell proportions (=artificial gold standard). Using these data, we can assess the performance of immune deconvolution tools. 4.1 Average fraction of tumour cells To obtain representatitive simulated samples, we are interested in the average fraction of tumour cells vs immune cells in a mixture. Figure 4.1: proportion of cell types by tumor sample cancer_cell_param = MASS::fitdistr(cancer_cells$freq, &quot;normal&quot;) The cancer fraction is \\(\\sim\\mathcal{N}(0.33, 0.3)\\). 4.2 Create simulated bulk tissues The fractions of a sample are randomly assigned in the following procedure: Draw a random tumour cell content from the distribution fitted above The first half of the samples will use melanoma cells, the second half ovarian cancer cells. Assign the remaining fraction (=not cancer cells) randomly to the remaining cell types (B cell, T cell CD8+, Melanoma cell, T cell CD4+ (non-regulatory), Macrophage/Monocyte, T cell regulatory (Tregs), Cancer associated fibroblast, Dendritic cell, Endothelial cell, NK cell, PBMC, Ovarian carcinoma cell) Here, we generate a simulated bulk RNA-seq ExpressionSet: set.seed(42) bulk_eset = make_bulk_eset(eset=single_cell_schelker$eset, cell_fractions = cell_fractions, n_cells=500) 4.3 Run the deconvolution 4.4 Results The following methods have absolute (EPIC, quanTIseq) or pseudo-absolute (CIBERSORT abs. mode, xCell) scores, and we test how well they perform in terms of absolute deviation abs_methods ## [1] &quot;cibersort_abs&quot; &quot;epic&quot; &quot;quantiseq&quot; &quot;xcell&quot; We perform an evaluation for the following cell types. Note that some cell types are redundant (T cell CD4+ is a super-category of Tregs and non-regulatory CD4+ T cells). As some methods provide deconvolution only at the CD4+ level, we compare both categories: show_cell_types = c(&quot;B cell&quot;, &quot;Dendritic cell&quot;, &quot;Macrophage/Monocyte&quot;, &quot;NK cell&quot;, &quot;T cell CD4+&quot;, &quot;T cell CD4+ (non-regulatory)&quot;, &quot;T cell regulatory (Tregs)&quot;, &quot;T cell CD8+&quot;, &quot;Cancer associated fibroblast&quot;, &quot;Endothelial cell&quot;) The following methods do not have signatures to quantify “Macrophages/Monocytes”, but only a Macrophage signature. Unfortunately, our single cell dataset does not distinguish between Macrophages and Monocytes. As we are only comparing correlations here, we still benchmark the Macrophage signature on the “Macrophage/Monocyte” data, as an increase in both should also lead to an increase in Macrophages only. To be fair, we label the results accordingly. macrophage_signature_only = c(&quot;epic&quot;, &quot;timer&quot;) Here, we map the results back to the “gold standard”. We aggregate the results of the different methods into a single table and clean it up for further processing. results_with_gold_standard = inner_join(all_results_tidy, gold_standard, by=c(&quot;sample&quot;, &quot;cell_type&quot;)) 4.4.1 Correlation plots Figure 4.2: The figure shows the correlation of predicted vs. known fractions on 100 simulated bulk RNA seq samples. 4.4.2 Calculate correlations for each method and cell type correlations_tab = correlations %&gt;% select(cell_type, method, pearson) %&gt;% spread(cell_type, pearson) write_tsv(correlations_tab, &quot;../results/tables/mixing_study_correlations.tsv&quot;, na=&quot;&quot;) Figure 4.3: Correlations of predicted vs. known fractions on 100 simulated bulk RNA-seq samples, organized by cell type. 4.4.3 Deviation from slope (x=y) for all absolute methods If the absolute devoncolution was perfect, the slope would equal 1 (\\(x \\mapsto y\\) ). The figure shows the deviation from the 1, i.e. values &gt; 0 indicate the method over-estimates the fraction of these cells; values &lt; 0 indicate the method under-estiamtes the fraction of these cells. Note that only EPIC and quanTIseq provide scores that can be interpreted as a cell fraction. xCell and CIBERSORT abs. scale the output score to be ‘absolute’: xCell does an attempt to make the scores resemble percentages, but it is a hard problem, and is very platform and experiment specific. (xCell on github Absolute mode scales relative cellular fractions into a score of arbitrary units that reflects the absolute proportion of each cell type in a mixture. Although not currently expressed as a fraction, the absolute score can be directly compared across cell types (i.e., relative differences between cell types are maintained) (cibersort FAQ) Confidence intervals are two-sided 95% confidence intervales derived using confint and lm. ## Warning in eval(substitute(expr), envir, enclos): NaNs produced ## Warning in eval(substitute(expr), envir, enclos): NaNs produced ## Warning in eval(substitute(expr), envir, enclos): NaNs produced Figure 4.4: Comparison of absolute methods. The bars indicate the log2(slope). Values &lt; 0 indicate an under-prediction of the cell type, values &gt; 0 an over-prediction respectively. ## Joining, by = c(&quot;method&quot;, &quot;cell_type&quot;) ## Warning: Removed 33 rows containing missing values (geom_text). (#fig:abs_rmse)Comparison of absolute methods. The values show the RMSE References "],
["validation-with-real-data.html", "5 Validation with real data 5.1 Between- and within-sample comparisons 5.2 Within-sample comparison 5.3 Between-sample comparisons", " 5 Validation with real data We use datasets which estimate the immune cell proportions using flow cytometry as an additional validation for our simulation benchmark. We use the following three validation datasets (see section 2): datasets = list( racle=racle, hoek=hoek, schelker_ovarian=schelker_ovarian ) We use the following cell types, which are available in (some of) the datasets use_cell_types = c(&quot;T cell&quot;, &quot;T cell CD8+&quot;, &quot;T cell CD4+&quot;, &quot;Macrophage/Monocyte&quot;, &quot;B cell&quot;, &quot;Dendritic cell&quot;, &quot;NK cell&quot;, &quot;Neutrophil&quot;) Here, we combine the predictions with the ‘gold standard’ reference data. all_results_ref = inner_join(all_results, all_refs, by = c(&quot;sample&quot; = &quot;sample&quot;, &quot;dataset&quot; = &quot;dataset&quot;, &quot;cell_type&quot; = &quot;cell_type&quot;)) res_validation$all_results = all_results_ref The scores of the methods have different properties and not all of them are directly comparable. We distinguish between three types of comparisons: absolute scores: allow to compare within and between samples. scores relative to the total immune cell content: allow to compare within a sample scores in arbitrary units, that only allow to compare between samples. Here, we assign the methods to their respective group: abs_methods = c(&quot;cibersort_abs&quot;, &quot;quantiseq&quot;, &quot;epic&quot;) within_methods = c(&quot;cibersort&quot;, &quot;cibersort_abs&quot;, &quot;quantiseq&quot;, &quot;epic&quot;) between_methods = c(&quot;cibersort_abs&quot;, &quot;quantiseq&quot;, &quot;epic&quot;, &quot;timer&quot;, &quot;xcell&quot;, &quot;mcp_counter&quot;) 5.1 Between- and within-sample comparisons Only works for methods providing an absolute score (cibersort_abs, quantiseq, epic). All other methods are included for reference. Figure 5.1: Comparison of absolute predictions for three validation dataset. Figure 5.2: Comparison of absolute methods. The bars indicate the log2(slope). Values &lt; 0 indicate an under-prediction of the cell type, values &gt; 0 an over-prediction respectively. -Inf indicates that the correlation coefficient is negative. ## Warning: Removed 22 rows containing missing values (geom_text). (#fig:abs_rmse_val)Comparison of absolute methods. The values show the RMSE 5.2 Within-sample comparison only works with methods that provide an absolute score, or a score that is relative to total immune cell content (cibersort, cibersort_abs, quantiseq, epic). Figure 5.3: Comparison of predictions within each individual sample Compute the average over all samples: Figure 5.4: Correlations of within-sample comparisons. The last column shows the mean over all samples. 5.3 Between-sample comparisons For this, we need to look at every cell type independently. Works for all methods except CIBERSORT. Figure 5.5: Correlations of known vs. predicted fractions for each cell type independenctly. The ‘Tcell’ column corresponds to the amount of profiled total T cells or the sum of CD4+ and CD8+ T cells respectively. Compute the average over all cell types. We only use cell types with at least 5 samples to obtain reasonable correlation estimates. We also exclude the T-cell supercategory to avoid redundancies. use_cell_types2 = c(&quot;B cell&quot;, &quot;Dendritic cell&quot;, &quot;Macrophage/Monocyte&quot;, &quot;NK cell&quot;, &quot;T cell CD4+&quot;, &quot;T cell CD8+&quot;) Figure 5.6: Performance on validation datasets by cell type. The last column shows the mean over all cell types. Note that, although the correlation for CD8+ T cells looks bad, it does not necessarily mean the predictions are bad. There is just little variance between the samples and CD8+ T cell abundance is generally low, which is correlctly predicted by the methods. "],
["detection-limit-and-false-positive-predictions.html", "6 Detection limit and false positive predictions 6.1 Predictions with increasing immune cell content 6.2 Detection Limit 6.3 False-positive predictions", " 6 Detection limit and false positive predictions How many cells of a certain type do we need for a method to detect immune cell infiltration? (=Detection limit) How many cells of a certain type are detected, although we know they are not there? (=false positives) We again use the single cell dataset to simulate samples that consist of background cells (i.e. non-immune cells: fibroblasts, endothelial cells cancer cells) and add an increasing amount of immune cells of a certain type. We define the detection limit as the minimal fraction at which the method the abundance of the cell type to be significantly different from zero. We define false positives as the predicted fraction of a certain cell type at zero inflitration level. For each amount of immune cells, we generate 5 random samples to compute a confidence interval. We use the following cell types: show_cell_types = c(&quot;B cell&quot;, &quot;Dendritic cell&quot;, &quot;Macrophage/Monocyte&quot;, &quot;NK cell&quot;, &quot;T cell CD4+&quot;, &quot;T cell CD8+&quot;) 6.1 Predictions with increasing immune cell content Figure 6.1: We add an increasing amount of each cell type independently to the 1,800 background cells. The figure shows the predictions for each cell type and method at increasing infiltration levels. 6.2 Detection Limit ## Warning: Removed 2 rows containing missing values (geom_text). Figure 6.2: Sensitivity of the methods per cell type. The bars indicate the minimal percentage of infiltration at which the method first reliably detects the cell type. Opaque bars indicate that the methods does not provide an estimate for the cell type. 6.3 False-positive predictions Predicted amount of cells when there are none. This analysis is based on all of the data above where only background cells are present, i.e. fraction of immune cells = 0. Figure 6.3: Predicted amount of a certain cell type while it is actually absent. "],
["spillover-analysis.html", "7 Spillover Analysis 7.1 Complete Spillover Matrix 7.2 Summary figure: Signal to noise ratio 7.3 Summary figure: migration charts 7.4 Investigate marker genes 7.5 Check expression of markers in “detection limit” simulation dataset. 7.6 Deconvolution results before and after", " 7 Spillover Analysis In this chapter, we investigate which other cell types a method predicts, if there is actually only a certain cell type present. In FACS, this phenomenon is known as “spillover”. To this end, we use three datasets immune reference: bulk RNA seq profiles from sorted immune cells (=quanTIseq training data) artificial bulk: simulated bulk RNA seq profiles from single cells (e.g. only T cells) artificial bulk with background: simulated bulk RNA seq profiles from single cells with ~80% other cells (cancer, fibroblasts, …) We test the following cell types: show_cell_types = c(&quot;B cell&quot;, &quot;Dendritic cell&quot;, &quot;Macrophage/Monocyte&quot;, &quot;NK cell&quot;, &quot;T cell CD4+&quot;, &quot;T cell CD8+&quot;) 7.1 Complete Spillover Matrix Figure 7.1: This figure shows the spillover for all methods, cell types and datasets 7.2 Summary figure: Signal to noise ratio Noise is defined as the sum of all predictions of other cell types than the one that is actually present. Signal is defined as the predicted fraction of the cell type that is actually present. The signal ratio is defined as \\(\\frac{\\text{signal}}{\\text{signal+noise}}\\). Higher values indicate less noise (i.e. predictions of cell types that are not there). Figure 7.2: Signal ratios for each cell type and dataset. 7.3 Summary figure: migration charts Download this figure as high quality pdf Figure 7.3: migration charts for all three dataset. The value in the middle of the chart indicates the ‘noise ratio’, i.e. the sum of all false positive predictions. 7.4 Investigate marker genes We asked which marker genes drive the spillover from Dendritic cells to B cells. mat = cbind(pData(single_cell_schelker$eset), t(exprs(single_cell_schelker$eset))) %&gt;% as_tibble() mat = mat %&gt;% filter(source != &quot;pbmc&quot;) First, we suspected that the effect might be due to misannotations in the single cell dataset. Here, we show the B cells and DCs in the t-SNE plot of the single cell dataset. Figure 7.4: B cell and DC clusters in the single cell dataset. We observe that both clusters are distinct and non-overlapping. Next, we look for the expression of typical marker genes of DCs and B cells. ## [[1]] ## ## [[2]] ## ## [[3]] ## ## [[4]] ## ## [[5]] ## ## [[6]] ## ## [[7]] Conclusion: The B cell and DC cluster separate well, the marker genes do not overlap. The DC cluster are plasmacytoid DCs, mDCs are somewhere hidden in the Macrophage/Monocyte cluster and cannot be distinguished. 7.5 Check expression of markers in “detection limit” simulation dataset. markers = list( &quot;B cell&quot; = c(&quot;MS4A1&quot;, #=CD20 &quot;CD19&quot;, &quot;CD22&quot; ), &quot;myleoid&quot; = c(&quot;ITGAM&quot;, &quot;ITGAX&quot;), #=CD11B,CD11C &quot;MHC class II&quot; = c(&quot;HLA-DRB1&quot;, &quot;HLA-DRA&quot;), &quot;plasmacytoid DC&quot; = c(&quot;CLEC4C&quot;, &quot;IL3RA&quot;)) Figure 7.5: Correlation of marker genes with increase of the amount of a certain cell type. Along x-axis: cell type used for simulation. Along y-axis: groups of marker genes. Figure 7.6: Even though the number of dendritic cells does correlate with MS4A1, a B cell marker, the absolute expression is really low. This effect can be driven by few misclassified cells but cannot explain the spillover effects we observe. 7.5.1 Derive marker genes from quanTIseq/EPIC signature matrices. We use gini-index (Zhang et al. (2017), BMC genomics) to filter for highly discriminating genes within the matrix. We select all genes with a gini index &gt; 0.7. We assign all selected genes as marker gene to the cell type in which it is expressed the most. In the end, we receive a list of signature genes for each cell type. til10 = read_tsv(&quot;../immunedeconv/inst/extdata/quantiseq/TIL10_signature.txt&quot;) %&gt;% as.data.frame() %&gt;% column_to_rownames(&quot;ID&quot;) The same procedure is applied to EPIC and CIBERSORT. See figures: * EPIC * quanTIseq * CIBERSORT The figures show the expression of marker genes across cell types. Along x-axis: cell types used for simulation. Along y-axis: signature genes for the cell types derived from the signature matrices of the deconvolution methods. 7.6 Deconvolution results before and after Figure 7.7: Predictions on 10 simulated DC samples before and after removal of the five genes. "],
["creating-publication-ready-figures.html", "8 Creating publication ready figures 8.1 Benchmark results, detection limit, false positives and absolute deviation 8.2 Migration charts for Spillover analysis", " 8 Creating publication ready figures 8.1 Benchmark results, detection limit, false positives and absolute deviation Figure 8.1: Benchmark results main figure. 8.2 Migration charts for Spillover analysis # Plot differences with removed marker genes rmgenes_plot = res_spillover$rm_marker_genes %&gt;% inner_join(method_names) %&gt;% filter(cell_type == &quot;B cell&quot;) %&gt;% mutate(dataset = if_else(dataset == &quot;before&quot;, &quot;no&quot;, &quot;yes&quot;)) %&gt;% ggplot(aes(x=dataset, y=predicted_fraction, colour=dataset)) + geom_quasirandom() + stat_summary(fun.y=mean, geom=&quot;crossbar&quot;, fun.ymin=mean, fun.ymax=mean, width=.5, color=&quot;black&quot;) + facet_wrap(~method_name, drop = TRUE) + stat_compare_means(paired = TRUE, method = &quot;t.test&quot;, label=&quot;p.signif&quot;) + theme(legend.position = &quot;none&quot;) + xlab(&quot;signature genes removed&quot;) + ylab(&quot;predicted fraction&quot;) + scale_color_brewer(type=&quot;qual&quot;, palette=2, direction = -1) + ylim(0, .75) ## Joining, by = &quot;method&quot; ## Warning: Column `method` joining character vector and factor, coercing into ## character vector Figure 8.2: Migration chart figure for paper. "],
["references.html", "9 References", " 9 References "]
]
