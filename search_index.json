[
["index.html", "Immune Deconvolution Benchmark 1 Introduction 1.1 Conceptual differences between methods", " Immune Deconvolution Benchmark Gregor Sturm 2018-06-19 1 Introduction There is urgent need for an unbiased comparison of existing immune deconvolution methods. We focus on RNA-seq only in this review, as current data, including large public efforts like TCGA, are likely generated using this technology. To our best knowlege, no such benchmark study has been performed yet, maybe due to the lack of an appropriate gold standard. Now, with the advent of large, publicly availble single-cell datasets this such a comparison becomes feasible. Systematic, methodological comparisons of such methods are available (Newman and Alizadeh 2016; Finotello and Trajanoski 2018; Avila Cobos et al. 2018). Here, we focus on algorithms, specifically developed for tumour immune cell deconvolution shipping with the appropriate signature matrix. While other, generic deconvolution altorithms are available (also reviewd in Finotello and Trajanoski (2018)), we do not take them into account here, as the resulting performance depends at least as much on the signature as on the method. The methods: MCPCounter (Becht et al. 2016) xCell (Aran, Hu, and Butte 2017) CIBERSORT (Aaron M. Newman, Chih Long Liu, Michael R. Green, Andrew J. Gentles, Weiguo Feng, Yue Xu, Chuong D. Hoang, Maximilian Diehn, A., and Alizadeh 2016) TIMER (B. Li et al. 2016) EPIC (Racle et al. 2017) quanTIseq (Finotello et al. 2017) TODO refer schelker paper 1.1 Conceptual differences between methods There are three conceptually different approaches to deconvolution. First, one can try to achieve scores suitable for inter-sample comparison. In that case, one can ask “Do I have more T cells in sample A than in sample B”, but one cannot ask “Do I have more B cells than T cells in sample A.”. This approach is used by GSEA-based methods like MCP counter. Second, one can try to build scores suitable for intra-sample comparison. In that case, one can ask “Do I have more B cells than T cells in sample A”, however one cannot draw conclusions about the abundance of T cells in sample A versus B, given there could also be other, unknown cell types in the sample (e.g. cancer cells). This approach is used by the default version of CIBERSORT) Last, ideally, one can build a score, that reflects the absolute quantity of a certain cell type in the sample. This approach allows both intra- and inter-sample comparisons. 1.1.1 Gene-set based methods (allow comparison between samples, but not between cell types) xCell (the authors apply some sort of normalization that makes xCell scores resemble percentages, although they advise doing this analysis with caution (ref). In this Benchmark, we will nonetheless try xCell both as “relative” and “absolute” method. MCPCounter (purely gene-expression based -&gt; between cell type comparison is simply wrong) TIMER (“not comparable between cancer types or different immune cells”) 1.1.2 Deconvolution-based methods (relative fractions, allow comparisons between cell types, but not samples) “relative to the total immune content” CIBERSORT (default mode) 1.1.3 Deconvolution-based methods (absolute fractions, allow comparisons between cell types and samples) CIBERSORT absolute mode (“Absolute mode scales relative cellular fractions into a score of arbitrary units that reflects the absolute proportion of each cell type in a mixture. Although not currently expressed as a fraction, the absolute score can be directly compared across cell types (i.e., relative differences between cell types are maintained)” [cibersort FAQ]) quanTIseq (uses cell fractions) EPIC (uses cell fractions) As CIBERSORT absolute scores are expressed in arbitrary units and not fractions, estimating the abundance of “Other cells” can be misleading. We will still try… References "],
["input-data.html", "2 Input data 2.1 cell type hierarchy 2.2 Single cell data for simulated mixtures 2.3 Immune cell bulk reference samples (quanTIseq training data) 2.4 Validation data (RNAseq + matched gold standard)", " 2 Input data In this chapter, we load and preprocess the different input datasets. We use a dedicated environment for each dataset in order not to trash the global namespace. 2.1 cell type hierarchy We use a hierachy of immune cell types to map the cell types between different datasets. Here is the hierachy visualized: 2.2 Single cell data for simulated mixtures In this study, we make use of the single cell dataset curated by (Schelker et al. 2017). They aggregated single cell sequencing data from different sources resulting in a set of ~12,000 single cells. They classified the cells using at set of 45 marker genes into 11 categories: 2 cancer types (Melanoma cell, Ovarian carcinoma cell), 0 immune cells (), 2 other cells (Cancer associated fibroblast, Endothelial cell) and Unknown cells which could not have been classified unambiguously. Unknown cells are excluded from the downstream analysis. The dataset consists of single cells from PBMC, melanoma and ovarian cancer ascites. As we are interested in the deconvolution of cancer samples, we exclude the PBMC cells from all downstream analyses. the ~12,000 samples by cell type cell_type n B cell 646 Cancer associated fibroblast 132 Dendritic cell 140 Endothelial cell 71 Macrophage/Monocyte 2227 Melanoma cell 1310 NK cell 198 Ovarian carcinoma cell 300 T cell CD4+ (non-regulatory) 1196 T cell CD8+ 1130 T cell regulatory (Tregs) 142 Figure 2.1: tSNE-clustering of the ~12000 single cells from (Schelker et al. 2017). 2.3 Immune cell bulk reference samples (quanTIseq training data) 2.4 Validation data (RNAseq + matched gold standard) e.g. IHC, Flow cytometry, single cell 2.4.1 Hoeck data 8 PBMC, RNAseq+flow cytometry Measured cell types: T cell, Macrophage/Monocyte, B cell, Dendritic cell, NK cell. 2.4.2 Schelker data Load the data and merge replicates. 3 ovarian cancer ascites samplese which have matched flow cytometry/single cell/bulk data. Single cell count for the 3 samples donor sum(cell_count) 7873M 864 7882M 902 7892M 773 2.4.3 Racle data 4 metastatic melanoma, matched bulkRNAseq with FlowCytometry. References "],
["validitiy-of-single-cell-rna-seq-as-reference.html", "3 Validitiy of single cell RNA-seq as reference 3.1 Validity of simulated bulk tissues from single cell sequencing data 3.2 Correlated simulated samples with bulk of the same tissue.", " 3 Validitiy of single cell RNA-seq as reference Schelker et al. (2017) have shown that measurements from single cell sequencing are highly consistent with flow cytometry. 3.1 Validity of simulated bulk tissues from single cell sequencing data We use simulated samples from single cell gene expression data. Does this approach make sense after all? We have 3 samples of single cell samples matched to bulk RNA sequencing. To test, we try: correlation of the simulated gene expression with the measured bulk gene expression. correlation of the predicted fractions with all methods on bulk vs. simulated tissue. correlation of the simulated gene expression with bulk gene expression from the same tissue. 3.1.1 Compare simululated samples to bulk samples Simulate bulk samples by summing up the expression values of all cells. Theoretically, it should not matter whether to use sum or mean as they only differ by a constant scaling factor. However, we ran into numerical issues with CIBERSORT and quanTIseq using mean, as the valuese are much smaller. bulk_sum = sapply(colnames(schelker_ovarian$expr_mat), function(donor) { ind = pData(single_cell_schelker$eset)$donor == donor apply(exprs(single_cell_schelker$eset)[,ind], 1, sum) }) Figure 3.1: Correlation of bulkRNAseq data vs. simulated bulk data. Data has been log-tranformed We observe a good correlation, although one can argue that it is very noisy and far from perfect. We do not draw any conclusions from this plot. 3.1.2 Compare the predicted fractions We run all methods on both datasets and compare the results. The results suggest a reasonable correlation between the estimates on bulkRNAseq and simulated bulkRNAseq. The results depend on the method, however. The very good agreement of EPIC and MCPCounter suggest, that the methodology itself is valid; just some methods appear to be more dependent on noise than others. xCell does not pick up a signal here as is “does not work on homogeneous samples”, as stated on their github page. 3.2 Correlated simulated samples with bulk of the same tissue. We generate simulated bulk tissues of various cell types and correlate them with bulk RNA seq samples from sorted cells. In general, the highest correlation is observed between the expression of the sorted cells and the simulated bulk sample. However, the simulated Dendritic cells do not correlate well with any of the reference profiles. References "],
["mixing-study.html", "4 Mixing study 4.1 Average fraction of tumour cells 4.2 Create simulated bulk tissues 4.3 Run the deconvolution 4.4 Results", " 4 Mixing study In this chapter, we will use single cell data from (Schelker et al. 2017) to create simulated bulk RNAseq samples of which we know the true cell proportions. We futher use these samples to benchmark the performance of different recently published immune deconvolution tools. 4.1 Average fraction of tumour cells To obtain representatitive simulated samples, we are interested in the average fraction of tumour cells vs immune cells in a mixture. cancer_cell_param = MASS::fitdistr(cancer_cells$freq, &quot;normal&quot;) The mean cancer fraction is 0.33 ± 0.3. 4.2 Create simulated bulk tissues The fractions of a sample are randomly assigned in the following procedure: Draw a random tumour cell content from the distribution fitted above The first half of the samples will use melanoma cells, the second half ovarian cancer cells. Assign the remaining fraction (=not cancer cells) randomly to the remaining cell types (B cell, T cell CD8+, Melanoma cell, T cell CD4+ (non-regulatory), Macrophage/Monocyte, T cell regulatory (Tregs), Cancer associated fibroblast, Dendritic cell, Endothelial cell, NK cell, Ovarian carcinoma cell) Here, we generate a simulated bulkRNA Expressionset: set.seed(42) bulk_eset = make_bulk_eset(eset=single_cell_schelker$eset, cell_fractions = cell_fractions, n_cells=500) 4.3 Run the deconvolution We first run all methods that are integrated in the immune_deconvolution_methods are package automatically in a loop. all_results = foreach(method=immunedeconv::deconvolution_methods, .final = function(x) {setNames(x, immunedeconv::deconvolution_methods)}) %dopar% { deconvolute(bulk_eset, method, column=&quot;gene_symbol&quot;) } 4.3.1 run TIMER TIMER (B. Li et al. 2016) is only available as a web resource. Moreover, the algorithm is adapted for each cancer type, so that we have to choose the corresponding option (Melanoma/Ovarian) when running the algorithm. We therefore export the data required to run the algorithm and re-import the results obtained from the web-tool. eset_mat = eset_to_matrix(bulk_eset, &quot;gene_symbol&quot;) immunedeconv::export_for_timer(eset_mat[,is_melanoma], path=&quot;../results/timer/mixing/input_melanoma.tsv&quot;) immunedeconv::export_for_timer(eset_mat[,!is_melanoma], path=&quot;../results/timer/mixing/input_ovarian.tsv&quot;) # run web here... res_timer_melanoma = immunedeconv::import_from_timer(&quot;../results/timer/mixing/result_melanoma.csv&quot;) res_timer_ovarian = immunedeconv::import_from_timer(&quot;../results/timer/mixing/result_ovarian.csv&quot;) res_timer = inner_join(res_timer_melanoma, res_timer_ovarian, by=&quot;cell_type&quot;) 4.4 Results The following methods have absolute (EPIC, quanTIseq) or pseudo-absolute (CIBERSORT abs. mode, xCell) scores, and we test how well they perform in terms of absolute deviation abs_methods = c(&quot;cibersort_abs&quot;, &quot;epic&quot;, &quot;quantiseq&quot;, &quot;xcell&quot;) We perform an evaluation for the following cell types. Note that some cell types are redundant (T cell CD4+ is a super-category of Tregs and non-regulatory CD4+ T cells). As some methods provide deconvolution only at the CD4+ level, we compare both categories: show_cell_types = c(&quot;B cell&quot;, &quot;Dendritic cell&quot;, &quot;Macrophage/Monocyte&quot;, &quot;NK cell&quot;, &quot;T cell CD4+&quot;, &quot;T cell CD4+ (non-regulatory)&quot;, &quot;T cell regulatory (Tregs)&quot;, &quot;T cell CD8+&quot;, &quot;Cancer associated fibroblast&quot;, &quot;Endothelial cell&quot;) The following methods do not have signatures to quantify “Macrophages/Monocytes”, but only a Macrophage signature. Unfortunately, our single cell dataset does not distinguish between Macrophages and Monocytes. As we are only comparing correlations here, we still benchmark the Macrophage signature on the “Macrophage/Monocyte” data, as an increase in both should also lead to an increase in Macrophages only. To be fair, we label the results accordingly. macrophage_signature_only = c(&quot;epic&quot;, &quot;timer&quot;) Here, we map the results back to the “gold standard”. We aggregate the results of the different methods into a single table and clean it up for further processing. results_with_gold_standard = inner_join(all_results_tidy, gold_standard, by=c(&quot;sample&quot;, &quot;cell_type&quot;)) 4.4.1 Correlation plots 4.4.2 Calculate correlations for each method and cell type 4.4.3 Absolute error for all qualifying methods References "],
["validation-with-real-data.html", "5 Validation with real data", " 5 Validation with real data We the curated datasets with gold standard as an additional validation on top of the mixing study. We use the following three validation datasets (see table @ref(tab:validation_data)), which are the only ones in the tables for which we could obtain both gene expression and validation data datasets = list( racle=racle, hoeck=hoeck, schelker_ovarian=schelker_ovarian ) We use the following cell types, which are available in (some of) the datasets use_cell_types = c(&quot;T cell&quot;, &quot;T cell CD8+&quot;, &quot;T cell CD4+&quot;, &quot;Macrophage/Monocyte&quot;, &quot;B cell&quot;, &quot;Dendritic cell&quot;, &quot;NK cell&quot;, &quot;Neutrophil&quot;) ## Parsed with column specification: ## cols( ## sampleID = col_character(), ## B_cell = col_double(), ## T_cell.CD4 = col_double(), ## T_cell.CD8 = col_double(), ## Neutrophil = col_double(), ## Macrophage = col_double(), ## DC = col_double() ## ) ## Parsed with column specification: ## cols( ## sampleID = col_character(), ## B_cell = col_double(), ## T_cell.CD4 = col_double(), ## T_cell.CD8 = col_double(), ## Neutrophil = col_double(), ## Macrophage = col_double(), ## DC = col_double() ## ) ## Parsed with column specification: ## cols( ## sampleID = col_character(), ## B_cell = col_double(), ## T_cell.CD4 = col_double(), ## T_cell.CD8 = col_double(), ## Neutrophil = col_double(), ## Macrophage = col_double(), ## DC = col_double() ## ) Here, we combine the predictions with the ‘gold standard’ reference data. all_results_ref = inner_join(all_results, all_refs, by=c(&quot;sample&quot;=&quot;sample&quot;, &quot;dataset&quot;=&quot;dataset&quot;, &quot;cell_type&quot;=&quot;cell_type&quot;)) Observation: all methods work better on PBMC than they do on cancer cells. "],
["correlation-of-methods-across-tcga-samples-.html", "6 Correlation of methods across TCGA samples. 6.1 Heatmap clustered by correlation 6.2 Heatmap unclustered, sorted by cell type", " 6 Correlation of methods across TCGA samples. Next, we were interested how the predictions for different cell types correlate. To this end, we ran all methods on 10446 TCGA samples. If predictions for the same cell type of different methods correlate strongly, we can assume the signatures to be robust. If they do not cluster, the signatures are different and we can conclude, that potentially the cell-type is not well-defined. The data has been preprocessed elsewhere, and we obtain the estimates from our database. 6.1 Heatmap clustered by correlation pheatmap(tcga_cor, clustering_distance_rows = &quot;correlation&quot;, clustering_distance_cols = &quot;correlation&quot;) 6.2 Heatmap unclustered, sorted by cell type pheatmap(tcga_cor, cluster_rows = FALSE, cluster_cols = FALSE) "],
["sensitivity-analysis.html", "7 Sensitivity analysis 7.1 Predictions with increasing immune cell content", " 7 Sensitivity analysis How many cells do we need for a method to detect immune cell infiltration? We again use the single cell dataset to simulate samples that consist of background cells (i.e. non-immune cells: fibroblasts, endothelial cells cancer cells) and add an increasing amount of immune cells of a certain type. For each amount of immune cells, we generate 5 random samples to compute a confidence interval. We use the following cell types: show_cell_types = c(&quot;B cell&quot;, &quot;Dendritic cell&quot;, &quot;Macrophage/Monocyte&quot;, &quot;NK cell&quot;, &quot;T cell CD4+&quot;, &quot;T cell CD8+&quot;) We do not include TIMER in this analysis, as we cannot run it in an automated fashion. 7.1 Predictions with increasing immune cell content 7.1.1 Summary figure: At which percentage the method captures the cell type above noise level? 7.1.2 Summary figure: predicted amount of cells when there are none "],
["specificity-analysis.html", "8 Specificity Analysis 8.1 Complete Spillover Matrix 8.2 Summary figure: Noise ratio", " 8 Specificity Analysis In this chapter, we investigate which other cell types a method predicts, if there is actually only a certain one. In FACS, this phenomenon is known as “spillover”. To this end, we create three datasets immune reference: bulk RNA seq profiles from sorted immune cells (=quanTIseq training data) artificial bulk: simulated bulk RNA seq profiles from single cells (e.g. only T cells) artificial bulk with background: simulated bulk RNA seq profiles from single cells with ~80% other cells (cancer, fibroblasts, …) We test the following cell types: show_cell_types = c(&quot;B cell&quot;, &quot;Dendritic cell&quot;, &quot;Macrophage/Monocyte&quot;, &quot;NK cell&quot;, &quot;T cell CD4+&quot;, &quot;T cell CD8+&quot;) We do not include TIMER in this analysis as we cannot run it in an automated fashion. ## Warning in EPIC::EPIC(bulk = gene_expression_matrix, ...): The optimization didn&#39;t fully converge for some samples: ## SRR1551070; SRR1740062; SRR452331; SRR1551055; SRR1551048; SRR1740046; SRR1551073; SRR1551059; SRR1740050; SRR1740078; SRR1551057; ERR431583; ERR431606; ERR431601 ## - check fit.gof for the convergeCode and convergeMessage ## Warning in EPIC::EPIC(bulk = gene_expression_matrix, ...): mRNA_cell value ## unknown for some cell types: CAFs, Endothelial - using the default value of ## 0.4 for these but this might bias the true cell proportions from all cell ## types. ## Warning in EPIC::EPIC(bulk = gene_expression_matrix, ...): The optimization didn&#39;t fully converge for some samples: ## value10; value16; value18; value19; value20; value23; value24 ## - check fit.gof for the convergeCode and convergeMessage ## Warning in EPIC::EPIC(bulk = gene_expression_matrix, ...): mRNA_cell value ## unknown for some cell types: CAFs, Endothelial - using the default value of ## 0.4 for these but this might bias the true cell proportions from all cell ## types. ## Warning in EPIC::EPIC(bulk = gene_expression_matrix, ...): The optimization didn&#39;t fully converge for some samples: ## value17; value28 ## - check fit.gof for the convergeCode and convergeMessage ## Warning in EPIC::EPIC(bulk = gene_expression_matrix, ...): mRNA_cell value ## unknown for some cell types: CAFs, Endothelial - using the default value of ## 0.4 for these but this might bias the true cell proportions from all cell ## types. 8.1 Complete Spillover Matrix This figure shows the spillover for all methods, cell types and datasets 8.2 Summary figure: Noise ratio The noise ratio is defined as \\(\\frac{\\text{noise}}{\\text{signal+noise}}\\). Lower values indicate less noise (i.e. predictions of cell types that are not there). "],
["robustness-against-noise.html", "9 Robustness against noise 9.1 Result figures", " 9 Robustness against noise We use random samples from TCGA, add different noise levels and check how the predictions of the different method compare to the original predictions. First, we retrieve 100 random samples from TCGA: set.seed(42) samples = tbl(tcga_db, &quot;sample&quot;) %&gt;% select(sample) %&gt;% pull(sample) %&gt;% sample(100) sample_expr = tbl(tcga_db, &quot;expression&quot;) %&gt;% filter(sample %in% samples) %&gt;% select(sample, gene_symbol, tpm) %&gt;% collect() Then we add noise to the samples. Noise is \\(\\sim\\mathsf{N}(0, \\text{noise_level})\\). noise_levels = c(0, 1, 5, 10) sample_noise_mat = lapply(noise_levels, function(x) { tmp_mat = sample_mat + x * noise_mat colnames(tmp_mat) = paste0(colnames(sample_mat), &quot;_&quot;, x) tmp_mat }) sample_noise_mat = do.call(&quot;cbind&quot;, sample_noise_mat) We then run the deconvolution methods on both the original and the ‘noisy’ samples. We consider the following cell types show_cell_types = c(&quot;B cell&quot;, &quot;Dendritic cell&quot;, &quot;Macrophage/Monocyte&quot;, &quot;NK cell&quot;, &quot;T cell CD4+&quot;, &quot;T cell CD4+ (non-regulatory)&quot;, &quot;T cell regulatory (Tregs)&quot;, &quot;T cell CD8+&quot;, &quot;Cancer associated fibroblast&quot;, &quot;Endothelial cell&quot;) 9.1 Result figures 9.1.1 Correlations "],
["conclusions.html", "10 Conclusions", " 10 Conclusions (TODO) "],
["materials-and-methods.html", "11 Materials and Methods 11.1 Data acquisition 11.2 Validation datasets (Flow cytometry, scRNAseq, Imageing + matched RNA seq)", " 11 Materials and Methods (TODO) 11.1 Data acquisition For the single cell dataset by Schelker et al. (2017), we obtained the MATLAB source code deposited on figshare and used it to re-produced the dataset. The final dataset was exported to csv format in order to continue the main analysis in R. We obtained the 3 matched ovarian cancer bulk RNA samples from Schelker et al. (2017) (personal communication). 11.2 Validation datasets (Flow cytometry, scRNAseq, Imageing + matched RNA seq) Describe how the datasets were obtained References "],
["references.html", "12 References", " 12 References "]
]
