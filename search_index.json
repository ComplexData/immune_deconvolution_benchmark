[
["index.html", "Benchmarking methods for estimating immune cell abundance from bulk RNA-sequencing data (supplementary information) 1 Introduction", " Benchmarking methods for estimating immune cell abundance from bulk RNA-sequencing data (supplementary information) manuscript in preparation Gregor Sturm\\(^{1,2}\\) Tatsiana Aneichyk\\(^1\\) \\(^1\\)Pieris Pharmaceuticals GmbH, Lise-Meitner-Straße 30, 85354 Freising, Germany \\(^2\\)Experimental Bioinformatics, TUM School of Life Sciences Weihenstephan, Technical University of Munich, Maximus-von-Imhof-Forum 3, 85354 Freising, Germany 2018-10-02 1 Introduction This document is supplementary information for Sturm, G. and Aneichyk T. Benchmarking methods for estimating immune cell abundance from bulk RNA-sequencing data, Manuscript in preparation. This document elaborates step-by-step how we derive our results, shows supplementary figures to support our study and serves as an open-source pipeline to reproduce our results. The source code and instructions how to run the benchmark are available from GitHub: grst/immune_deconvolution_benchmark "],
["input-data.html", "2 Input data 2.1 cell type hierarchy 2.2 Single cell data for simulated mixtures 2.3 Immune cell reference samples 2.4 8 PBMC samples from Hoek et al. (2015) 2.5 3 ovarian cancer ascites samples from Schelker et al. (2017) 2.6 4 metastatic melanoma samples from Racle et al. (2017) 2.7 Data sanity checks", " 2 Input data In this chapter, we load and preprocess the datasets we use in this study Dataset Reference A dataset of more than 11,000 single cancer and immune cells, classified by cell type Schelker et al. (2017) 50 Immune cell reference samples from 5 studies Curated by Finotello et al. (2017) 3 ovarian cancer ascites samples (RNAseq + FACS) Schelker et al. (2017) 8 PBMC samples (RNAseq + FACS) Hoek et al. (2015) 4 metastatic melanoma samplese (RNAseq + FACS) Racle et al. (2017) 2.1 cell type hierarchy We use a hierachy of immune cell types to map the cell types between different methods and datasets. The following figure shows this hierarchy visualized as a tree Figure 2.1: Hierarchy of immune cell types used for mapping cell types between methods and datasets. 2.2 Single cell data for simulated mixtures In this study, we make use of the single cell dataset curated by Schelker et al. (2017). They aggregated single cell sequencing data from different sources resulting in a set of more than 11,000 single cells. They classified the cells using at set of 45 marker genes into 12 categories: 2 cancer types (Melanoma cell, Ovarian carcinoma cell), 7 immune cells (B cell, T cell CD8+, T cell CD4+ (non-regulatory), Macrophage/Monocyte, T cell regulatory (Tregs), Dendritic cell, NK cell), 2 other cells (Cancer associated fibroblast, Endothelial cell) and Unknown cells which could not have been classified unambiguously. Unknown cells are excluded from the downstream analysis. The dataset consists of single cells from PBMC, melanoma and ovarian cancer ascites. As we are interested in the deconvolution of cancer samples, we exclude the PBMC cells from all downstream analyses. Table 2.1: The 11434 single cells by cell type cell_type n B cell 646 Cancer associated fibroblast 132 Dendritic cell 140 Endothelial cell 71 Macrophage/Monocyte 2227 Melanoma cell 1310 NK cell 198 Ovarian carcinoma cell 300 PBMC 3942 T cell CD4+ (non-regulatory) 1196 T cell CD8+ 1130 T cell regulatory (Tregs) 142 Figure 2.2: tSNE-clustering of the ~12,000 single cells from Schelker et al. (2017). 2.3 Immune cell reference samples RNAseq samples of pure immune cells of 10 types from 5 studies curated by Finotello et al. (2017). Table 2.2: List of immune cell reference samples 2.4 8 PBMC samples from Hoek et al. (2015) Table 2.2: Flow cytometry estimates of Hoek et al. 2.5 3 ovarian cancer ascites samples from Schelker et al. (2017) Each sample has two technical replicates. We merge the two replicates by taking the mean for each gene. ## &lt;table&gt; ## &lt;caption&gt;(#tab:mytab)Flow cytometry estimates of Schelker et al. &lt;/caption&gt; ## &lt;/table&gt; The samples have also been profiled by single cell RNA sequencing. The following table shows the cell count for each sample. Table 2.3: Single cell count per ovarian cancer ascites sample. donor sum(cell_count) 7873M 864 7882M 902 7892M 773 2.6 4 metastatic melanoma samples from Racle et al. (2017) Table 2.2: Flow cytometry estimates of Racle et al. 2.7 Data sanity checks Here, we plot the distributions of the different gene expression datasets to ensure that everything looks like we expect it to, e.g. if all datasets are on non-log scale. Figure 2.3: Histogram of gene expression data of all datasets Figure 2.4: Histogram of log-tranformed gene expression data of all datasets The mean values of all datasets: mean(c(exprs(single_cell_schelker$eset))) mean(c(racle$expr_mat)) mean(c(schelker_ovarian$expr_mat)) mean(c(hoek$expr_mat)) mean(c(immune_cell_reference$expr_mat)) ## [1] 0.7163828 ## [1] 29.20031 ## [1] 35.24549 ## [1] 51.61823 ## [1] 17.04449 save.image(file=&quot;../results/cache/input_data.rda&quot;, compress=FALSE) References "],
["validitiy-of-single-cell-rna-seq-as-reference.html", "3 Validitiy of single cell RNA-seq as reference 3.1 Compare simululated to genuine bulk samples 3.2 Compare predicted fractions 3.3 Correlation with immune reference samples.", " 3 Validitiy of single cell RNA-seq as reference Since we rely on simulated bulk RNA-seq samples generated from scRNA-seq data, we first investigate if this approach is valid and will give reasonable estimates of the methods’s performances. To test, we try: correlation of simulated bulk samples with a corresponding genuine bulk sample. correlation of the predicted fractions with all methods on bulk vs. simulated samples. correlation of the simulated bulk samples with a reference immune cell sample of the same cell type. 3.1 Compare simululated to genuine bulk samples bulk_mean = sapply(colnames(schelker_ovarian$expr_mat), function(donor) { ind = pData(single_cell_schelker$eset)$donor == donor apply(exprs(single_cell_schelker$eset)[,ind], 1, mean) }) bulk_mean = apply(bulk_mean, 2, scale_to_million) Figure 3.1: Correlation of simulated bulk samples with corresponding genuine bulk RNA-seq samples. 3.2 Compare predicted fractions We run all methods on both datasets and compare the results. Figure 3.2: Correlation of the methods’ predictions on both simulated and genuine bulk RNA-seq samples The results show a strong correlation between both datasets and suggest that the approach is valid in general. The poor overlap of xCell is proabably due to the fact that there is little variance between the samples which xCell requires to compute a meaningful score (see their README on GitHub). To demonstrate that this is the case, we run xCell on the same sample, but this time include 50 immune cell reference samples in the run. By adding additional samples, we add additional variance which enables xCell to compute a meaningful score. Figure 3.3: Correlation of xCell’s prediction on both simulated and genuine bulk RNA-seq samples, including additional samples to increase the variance. 3.3 Correlation with immune reference samples. To demonstrate that the simulated bulk samples are also biologically meaningflu, we generate simulated bulk samples of different immune cell types and correlate them with reference profiles of pure immune cells. Figure 3.4: Correlation of simulated bulk samples of a certain immune cell type (y-axis) with immune cell reference samples (x-axis) In general, the highest correlation is observed between the expression of the sorted cells and the simulated bulk sample. However, the simulated Dendritic cells do not correlate well with any of the reference profiles. "],
["simulation-benchmark.html", "4 Simulation benchmark 4.1 Average fraction of tumour cells 4.2 Create simulated bulk tissues 4.3 Run the deconvolution 4.4 Results", " 4 Simulation benchmark In this chapter, we will use single cell data from Schelker et al. (2017) to create simulated bulk RNAseq samples of which we know the true cell proportions (=artificial gold standard). Using these data, we can assess the performance of immune deconvolution tools. 4.1 Average fraction of tumour cells To obtain representatitive simulated samples, we are interested in the average fraction of tumour cells vs immune cells in a mixture. Figure 4.1: proportion of cell types by tumor sample cancer_cell_param = MASS::fitdistr(cancer_cells$freq, &quot;normal&quot;) The cancer fraction is \\(\\sim\\mathcal{N}(0.33, 0.3)\\). 4.2 Create simulated bulk tissues The fractions of a sample are randomly assigned in the following procedure: Draw a random tumour cell content from the distribution fitted above The first half of the samples will use melanoma cells, the second half ovarian cancer cells. Assign the remaining fraction (=not cancer cells) randomly to the remaining cell types (B cell, T cell CD8+, Melanoma cell, T cell CD4+ (non-regulatory), Macrophage/Monocyte, T cell regulatory (Tregs), Cancer associated fibroblast, Dendritic cell, Endothelial cell, NK cell, PBMC, Ovarian carcinoma cell) Here, we generate a simulated bulk RNA-seq ExpressionSet: set.seed(42) bulk_eset = make_bulk_eset(eset=single_cell_schelker$eset, cell_fractions = cell_fractions, n_cells=500) 4.3 Run the deconvolution 4.4 Results The following methods have absolute (EPIC, quanTIseq) or pseudo-absolute (CIBERSORT abs. mode, xCell) scores, and we test how well they perform in terms of absolute deviation abs_methods ## [1] &quot;cibersort_abs&quot; &quot;epic&quot; &quot;quantiseq&quot; &quot;xcell&quot; We perform an evaluation for the following cell types. Note that some cell types are redundant (T cell CD4+ is a super-category of Tregs and non-regulatory CD4+ T cells). As some methods provide deconvolution only at the CD4+ level, we compare both categories: show_cell_types = c(&quot;B cell&quot;, &quot;Dendritic cell&quot;, &quot;Macrophage/Monocyte&quot;, &quot;NK cell&quot;, &quot;T cell CD4+&quot;, &quot;T cell CD4+ (non-regulatory)&quot;, &quot;T cell regulatory (Tregs)&quot;, &quot;T cell CD8+&quot;, &quot;Cancer associated fibroblast&quot;, &quot;Endothelial cell&quot;) The following methods do not have signatures to quantify “Macrophages/Monocytes”, but only a Macrophage signature. Unfortunately, our single cell dataset does not distinguish between Macrophages and Monocytes. As we are only comparing correlations here, we still benchmark the Macrophage signature on the “Macrophage/Monocyte” data, as an increase in both should also lead to an increase in Macrophages only. To be fair, we label the results accordingly. macrophage_signature_only = c(&quot;epic&quot;, &quot;timer&quot;) Here, we map the results back to the “gold standard”. We aggregate the results of the different methods into a single table and clean it up for further processing. results_with_gold_standard = inner_join(all_results_tidy, gold_standard, by=c(&quot;sample&quot;, &quot;cell_type&quot;)) 4.4.1 Correlation plots Figure 4.2: The figure shows the correlation of predicted vs. known fractions on 100 simulated bulk RNA seq samples. 4.4.2 Calculate correlations for each method and cell type correlations_tab = correlations %&gt;% select(cell_type, method, pearson) %&gt;% spread(cell_type, pearson) write_tsv(correlations_tab, &quot;../results/tables/mixing_study_correlations.tsv&quot;, na=&quot;&quot;) Figure 4.3: Correlations of predicted vs. known fractions on 100 simulated bulk RNA-seq samples, organized by cell type. 4.4.3 Deviation from slope (x=y) for all absolute methods If the absolute devoncolution was perfect, the slope would equal 1 (\\(x \\mapsto y\\) ). The figure shows the deviation from the 1, i.e. values &gt; 0 indicate the method over-estimates the fraction of these cells; values &lt; 0 indicate the method under-estiamtes the fraction of these cells. Note that only EPIC and quanTIseq provide scores that can be interpreted as a cell fraction. xCell and CIBERSORT abs. scale the output score to be ‘absolute’: xCell does an attempt to make the scores resemble percentages, but it is a hard problem, and is very platform and experiment specific. (xCell on github Absolute mode scales relative cellular fractions into a score of arbitrary units that reflects the absolute proportion of each cell type in a mixture. Although not currently expressed as a fraction, the absolute score can be directly compared across cell types (i.e., relative differences between cell types are maintained) (cibersort FAQ) Confidence intervals are two-sided 95% confidence intervales derived using confint and lm. ## Warning in eval(substitute(expr), envir, enclos): NaNs produced ## Warning in eval(substitute(expr), envir, enclos): NaNs produced ## Warning in eval(substitute(expr), envir, enclos): NaNs produced Figure 4.4: Comparison of absolute methods. The bars indicate the log2(slope). Values &lt; 0 indicate an under-prediction of the cell type, values &gt; 0 an over-prediction respectively. ## Joining, by = c(&quot;method&quot;, &quot;cell_type&quot;) ## Warning: Removed 33 rows containing missing values (geom_text). (#fig:abs_rmse)Comparison of absolute methods. The values show the RMSE References "],
["validation-with-real-data.html", "5 Validation with real data 5.1 Between- and within-sample comparisons 5.2 Within-sample comparison 5.3 Between-sample comparisons", " 5 Validation with real data We use datasets which estimate the immune cell proportions using flow cytometry as an additional validation for our simulation benchmark. We use the following three validation datasets (see section 2): datasets = list( racle=racle, hoek=hoek, schelker_ovarian=schelker_ovarian ) We use the following cell types, which are available in (some of) the datasets use_cell_types = c(&quot;T cell&quot;, &quot;T cell CD8+&quot;, &quot;T cell CD4+&quot;, &quot;Macrophage/Monocyte&quot;, &quot;B cell&quot;, &quot;Dendritic cell&quot;, &quot;NK cell&quot;, &quot;Neutrophil&quot;) Here, we combine the predictions with the ‘gold standard’ reference data. all_results_ref = inner_join(all_results, all_refs, by = c(&quot;sample&quot; = &quot;sample&quot;, &quot;dataset&quot; = &quot;dataset&quot;, &quot;cell_type&quot; = &quot;cell_type&quot;)) res_validation$all_results = all_results_ref The scores of the methods have different properties and not all of them are directly comparable. We distinguish between three types of comparisons: absolute scores: allow to compare within and between samples. scores relative to the total immune cell content: allow to compare within a sample scores in arbitrary units, that only allow to compare between samples. Here, we assign the methods to their respective group: abs_methods = c(&quot;cibersort_abs&quot;, &quot;quantiseq&quot;, &quot;epic&quot;) within_methods = c(&quot;cibersort&quot;, &quot;cibersort_abs&quot;, &quot;quantiseq&quot;, &quot;epic&quot;) between_methods = c(&quot;cibersort_abs&quot;, &quot;quantiseq&quot;, &quot;epic&quot;, &quot;timer&quot;, &quot;xcell&quot;, &quot;mcp_counter&quot;) 5.1 Between- and within-sample comparisons Only works for methods providing an absolute score (cibersort_abs, quantiseq, epic). All other methods are included for reference. Figure 5.1: Comparison of absolute predictions for three validation dataset. Figure 5.2: Comparison of absolute methods. The bars indicate the log2(slope). Values &lt; 0 indicate an under-prediction of the cell type, values &gt; 0 an over-prediction respectively. -Inf indicates that the correlation coefficient is negative. ## Warning: Removed 22 rows containing missing values (geom_text). (#fig:abs_rmse_val)Comparison of absolute methods. The values show the RMSE 5.2 Within-sample comparison only works with methods that provide an absolute score, or a score that is relative to total immune cell content (cibersort, cibersort_abs, quantiseq, epic). Figure 5.3: Comparison of predictions within each individual sample Compute the average over all samples: Figure 5.4: Correlations of within-sample comparisons. The last column shows the mean over all samples. 5.3 Between-sample comparisons For this, we need to look at every cell type independently. Works for all methods except CIBERSORT. Figure 5.5: Correlations of known vs. predicted fractions for each cell type independenctly. The ‘Tcell’ column corresponds to the amount of profiled total T cells or the sum of CD4+ and CD8+ T cells respectively. Compute the average over all cell types. We only use cell types with at least 5 samples to obtain reasonable correlation estimates. We also exclude the T-cell supercategory to avoid redundancies. use_cell_types2 = c(&quot;B cell&quot;, &quot;Dendritic cell&quot;, &quot;Macrophage/Monocyte&quot;, &quot;NK cell&quot;, &quot;T cell CD4+&quot;, &quot;T cell CD8+&quot;) Figure 5.6: Performance on validation datasets by cell type. The last column shows the mean over all cell types. Note that, although the correlation for CD8+ T cells looks bad, it does not necessarily mean the predictions are bad. There is just little variance between the samples and CD8+ T cell abundance is generally low, which is correlctly predicted by the methods. "],
["detection-limit-and-false-positive-predictions.html", "6 Detection limit and false positive predictions 6.1 Predictions with increasing immune cell content 6.2 Detection Limit 6.3 False-positive predictions", " 6 Detection limit and false positive predictions How many cells of a certain type do we need for a method to detect immune cell infiltration? (=Detection limit) How many cells of a certain type are detected, although we know they are not there? (=false positives) We again use the single cell dataset to simulate samples that consist of background cells (i.e. non-immune cells: fibroblasts, endothelial cells cancer cells) and add an increasing amount of immune cells of a certain type. We define the detection limit as the minimal fraction at which the method the abundance of the cell type to be significantly different from zero. We define false positives as the predicted fraction of a certain cell type at zero inflitration level. For each amount of immune cells, we generate 5 random samples to compute a confidence interval. We use the following cell types: show_cell_types = c(&quot;B cell&quot;, &quot;Dendritic cell&quot;, &quot;Macrophage/Monocyte&quot;, &quot;NK cell&quot;, &quot;T cell CD4+&quot;, &quot;T cell CD8+&quot;) 6.1 Predictions with increasing immune cell content Figure 6.1: We add an increasing amount of each cell type independently to the 1,800 background cells. The figure shows the predictions for each cell type and method at increasing infiltration levels. 6.2 Detection Limit ## Warning: Removed 2 rows containing missing values (geom_text). Figure 6.2: Sensitivity of the methods per cell type. The bars indicate the minimal percentage of infiltration at which the method first reliably detects the cell type. Opaque bars indicate that the methods does not provide an estimate for the cell type. 6.3 False-positive predictions Predicted amount of cells when there are none. This analysis is based on all of the data above where only background cells are present, i.e. fraction of immune cells = 0. Figure 6.3: Predicted amount of a certain cell type while it is actually absent. "],
["spillover-analysis.html", "7 Spillover Analysis 7.1 Complete Spillover Matrix 7.2 Summary figure: Signal to noise ratio 7.3 Summary figure: migration charts", " 7 Spillover Analysis In this chapter, we investigate which other cell types a method predicts, if there is actually only a certain cell type present. In FACS, this phenomenon is known as “spillover”. To this end, we use three datasets immune reference: bulk RNA seq profiles from sorted immune cells (=quanTIseq training data) artificial bulk: simulated bulk RNA seq profiles from single cells (e.g. only T cells) artificial bulk with background: simulated bulk RNA seq profiles from single cells with ~80% other cells (cancer, fibroblasts, …) We test the following cell types: show_cell_types = c(&quot;B cell&quot;, &quot;Dendritic cell&quot;, &quot;Macrophage/Monocyte&quot;, &quot;NK cell&quot;, &quot;T cell CD4+&quot;, &quot;T cell CD8+&quot;) 7.1 Complete Spillover Matrix Figure 7.1: This figure shows the spillover for all methods, cell types and datasets 7.2 Summary figure: Signal to noise ratio Noise is defined as the sum of all predictions of other cell types than the one that is actually present. Signal is defined as the predicted fraction of the cell type that is actually present. The signal ratio is defined as \\(\\frac{\\text{signal}}{\\text{signal+noise}}\\). Higher values indicate less noise (i.e. predictions of cell types that are not there). Figure 7.2: Signal ratios for each cell type and dataset. 7.3 Summary figure: migration charts Download this figure as high quality pdf Figure 7.3: migration charts for all three dataset. The value in the middle of the chart indicates the ‘noise ratio’, i.e. the sum of all false positive predictions. "],
["creating-publication-ready-figures.html", "8 Creating publication ready figures 8.1 Benchmark results, detection limit, false positives and absolute deviation 8.2 Migration charts for Spillover analysis", " 8 Creating publication ready figures 8.1 Benchmark results, detection limit, false positives and absolute deviation Figure 8.1: Benchmark results main figure. 8.2 Migration charts for Spillover analysis Figure 8.2: Migration chart figure for paper. "],
["references.html", "9 References", " 9 References "]
]
