# Validation with real data
```{r}
res_validation = new.env()

```
We the curated datasets with gold standard as an additional validation on top of the mixing study. 

We use the following three validation datasets (see table \@ref(tab:validation_data)), which are the only ones
in the tables for which we could obtain both gene expression and validation data
```{r, cache=TRUE}
datasets = list(
  racle=racle,
  hoek=hoek,
  schelker_ovarian=schelker_ovarian
)
```

We use the following cell types, which are available in (some of) the datasets
```{r}
use_cell_types = c("T cell", "T cell CD8+", "T cell CD4+",
                   "Macrophage/Monocyte", "B cell", 
                   "Dendritic cell", "NK cell", "Neutrophil")
```

```{r, echo=FALSE, cache=TRUE, message=FALSE, echo=FALSE, warning=FALSE, results='hide'}
# run deconvolution and include TIMER results

## process a deconvolution result
process_result = function(result, method, dataset_name) {
  result %>% 
    map_result_to_celltypes(use_cell_types, method) %>% 
    as_tibble(rownames="cell_type") %>% 
    na.omit() %>% 
    gather(sample, estimate, -cell_type) %>% 
    mutate(method=method, dataset=dataset_name)
}

timer_cancer_type = list(racle="SKCM", # actually PBMC
                         hoek="SKCM", 
                         schelker_ovarian="OV")


# Run the deconvolution...
all_results = foreach(dataset=datasets, dataset_name=names(datasets), .combine=bind_rows) %:%
  foreach(method = immunedeconv::deconvolution_methods, .combine=bind_rows) %do% {
    timer_indications = rep(timer_cancer_type[[dataset_name]], ncol(dataset$expr_mat))
    deconvolute(dataset$expr_mat, method, indications=timer_indications) %>%
      process_result(method, dataset_name)
}

all_refs = foreach(dataset=datasets, dataset_name=names(datasets), .combine=bind_rows) %do% {
  dataset$ref %>% 
    select(sample, cell_type, true_fraction) %>%
    spread(sample, true_fraction) %>% 
    map_result_to_celltypes(use_cell_types) %>% 
    as_tibble(rownames="cell_type") %>% 
    gather(sample, true_fraction, -cell_type) %>% 
    mutate(dataset=dataset_name) %>% 
    na.omit()
}
```

Here, we combine the predictions with the 'gold standard' reference data. 
```{r, cache=TRUE}
all_results_ref = inner_join(all_results, all_refs, 
                             by=c("sample"="sample", "dataset"="dataset", "cell_type"="cell_type"))

res_validation$all_results = all_results_ref
```

## Within-sample comparisons
First, we look at the overall correlation of all cell types. 
However, this comparison is unfair for most of the methods, as their scores only allow comparisons between samples and not between cell types. 

```{r}
abs_methods = c("cibersort_abs", "quantiseq", "epic")
within_methods = c("cibersort", "cibersort_abs", "quantiseq", "epic")
between_methods = c("cibersort_abs", "quantiseq", "epic", "timer", "xcell", "mcp_counter")
```

## Between- and within-sample correlations
Only works for methods providing an absolute score. 
All other methods are included for reference. 
```{r, fig.width=10, fig.height=16, echo=FALSE}
all_results_ref %>%
  mutate(dataset2 = dataset) %>%
  bind_rows(all_results_ref %>% mutate(dataset2 = "all")) %>% 
  filter(!(cell_type == "T cell" & dataset != "hoek")) %>% 
  ggplot(aes(x=true_fraction, y=estimate)) +
    geom_point(aes(color=cell_type, shape=dataset)) + 
    scale_color_manual(values=color_scales$validation) + 
    facet_grid(method~dataset2, scales = "free_y") + 
    theme_bw() + 
    theme(legend.position = "top",
          strip.text.x = element_text(size=9)) + 
    background_grid(major="xy") + 
    stat_cor() 
```

# Within-sample comparsions
only works with methods that provide an absolute score, or a score that is relative to total immune
cell content. 
```{r, fig.width=8, fig.height=12, echo=FALSE}
all_results_ref %>% 
  filter(method %in% within_methods) %>% 
  filter(!(cell_type == "T cell" & dataset != "hoek")) %>% 
  ggplot(aes(x=true_fraction, y=estimate)) +
    geom_point(aes(color=cell_type, shape=dataset)) + 
    scale_color_manual(values=color_scales$validation) + 
    facet_grid(sample~method, scales = "free_y") + 
    theme_bw() + 
    theme(legend.position = "right",
          strip.text.x = element_text(size=9),
          strip.text.y = element_text(size=7)) + 
    background_grid(major="xy") + 
    stat_cor(size=3) 


```

Compute the average over all samples:
```{r, fig.width=8, fig.height=3}
sample_correlations = all_results_ref %>%
  filter(method %in% within_methods) %>%
  filter(!(cell_type == "T cell" & dataset != "hoek")) %>%
  group_by(dataset, method, sample) %>%
  do(make_cor(.$true_fraction, .$estimate))

average = sample_correlations %>% 
  group_by(method) %>% 
  summarise(pearson = mean(pearson)) %>% 
  mutate(sample = "mean") %>% 
  mutate(dataset = "mean")

sample_correlations %>%
  bind_rows(average) %>% 
  mutate(pearson_text = if_else(pearson < 0, "< 0", as.character(round(pearson, 2))),
         pearson = if_else(pearson < 0, 0, pearson)) %>%
  ggplot(aes(x=sample, y=method)) +
    geom_tile(aes(fill=pearson)) +
    geom_text(aes(label=pearson_text), size=3) +
    scale_fill_distiller(type="div", palette = "RdYlGn", direction=1, values=c(0,1))  +
    theme(axis.text.x=element_text(angle = 90, vjust = .5, hjust=1))

res_validation$within_sample = average
```


# Between-sample comparisons
For this, we need to look at every cell type independently
```{r, fig.width=12, fig.height=12, echo=FALSE}
all_results_ref %>%
  # filter(!(cell_type == "T cell" & dataset != "hoek")) %>% 
  ggplot(aes(x=true_fraction, y=estimate)) +
    geom_point(aes(color=cell_type, shape=dataset)) + 
    scale_color_manual(values=color_scales$validation) + 
    facet_grid(method~cell_type, scales = "free_y") + 
    theme_bw() + 
    theme(legend.position = "top",
          strip.text.x = element_text(size=9)) + 
    background_grid(major="xy") + 
    stat_cor(method='pearson') 
```

Compute the average over all cell types. 
We only use cell types with at least 5 samples to obtain reasonable 
correlation estimates. We also exclude the T-cell supercategory to 
avoid redundancies.

```{r}
use_cell_types2 = c("B cell", "Dendritic cell", "Macrophage/Monocyte", "NK cell", "T cell CD4+", "T cell CD8+")
```

```{r, fig.width=5, fig.height=3}
cell_type_correlations = all_results_ref %>%
#   filter(method %in% between_methods) %>%
  filter(cell_type %in% use_cell_types2) %>%
  group_by(cell_type, method) %>%
  do(make_cor(.$true_fraction, .$estimate))

average = cell_type_correlations %>% 
  group_by(method) %>% 
  summarise(pearson = mean(pearson)) %>% 
  mutate(cell_type = "mean") 

cell_type_correlations %>%
  bind_rows(average) %>% 
  ungroup() %>%
  mutate(pearson_text = if_else(pearson < 0, "< 0", as.character(round(pearson, 2))),
         pearson = if_else(pearson < 0, 0, pearson)) %>%
  mutate(cell_type = factor(cell_type, levels = c(sort(use_cell_types2), "mean"))) %>% 
  ggplot(aes(x=cell_type, y=method)) +
    geom_tile(aes(fill=pearson)) +
    geom_text(aes(label=pearson_text), size=3) +
    scale_fill_distiller(type="div", palette = "RdYlGn", direction=1, values=c(0,1))  +
    theme(axis.text.x=element_text(angle = 90, vjust = .5, hjust=1))


res_validation$between_sample_average = average
res_validation$between_sample = cell_type_correlations
```


Note that, although the correlation for CD8+ T cells looks bad, it does not necessarily mean the predictions are bad. There is just little variance between the samples and CD8+ T cell abundance is generally low, which is correlctly predicted by the methods. 

